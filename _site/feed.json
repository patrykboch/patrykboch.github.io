{
    "version": "https://jsonfeed.org/version/1",
    "title": "boch.dev",
    "home_page_url": "http://localhost:4000/",
    "feed_url": "http://localhost:4000/feed.json",
    "description": "Dull notes about Ruby and JS.",
    "icon": "http://localhost:4000/apple-touch-icon.png",
    "favicon": "http://localhost:4000/favicon.ico",
    "expired": false,
    
    "author":  {
        "name": "Patryk",
        "url": "boch.dev",
        "avatar": null
    },
    
"items": [
    
        {
            "id": "http://localhost:4000/2022/08/20/updating-to-react-18",
            "title": "React moved into adulthood. Reflections on updating React to v18",
            "summary": "Thoughts on updating to v18 in a big Typescript project",
            "content_text": "React 18 is out. I mean… it’s been available for over four months and I’ve just finished a kinda challenging process of migration from 17 to 18 in a huge JS app which is a mature SaaS product. I guess I completed it since you never know when the monster named tech debt could bite you. Anyways, I’d want to share some views on updating to 18v here, in the hopes that someone would find them useful.If you’re unfamiliar with the topic of version 18, read the official docs of the latest React.The new APIBefore considering bumping, please note - React’s most significant API has been modified. This means the commonly known and essential root mounting with ReactDOM.render is deprecated. Of course, it’s still supported (due to backward compatibility), but it produces irritating warnings in production env and floods specs run. Hint: a crazy spy may save us from the warnings flood in a spec run, but nothing will help in production except replacing the old API with the desired new ReactDOMClient.createRoot.  Only the use of the createRoot API enables all React 18 features; otherwise, it behaves like v17. It’s not worth updating if you don’t have time to refactor.I once went to a tech conference where one of the speakers was convincing the audience that it’s not crazy to consider releasing tech products with a failure. Failures bring crises, crises - the best solutions. I don’t take a stupid warning a failure, but what is most important the API replacement may fail in big JS projects of course. I assume the cost of the bump, disappointment, wasted time, tech debt to pay off etc. Maybe it’s not worth making it at this time, following the YAGNI principle. So, before updating the API in crucial parts, consider what would your customers do if an app didn’t work for one hour? Especially when test coverages are not credible and only a happy path is checked on your CI. That was not my case, but it’s worth asking questions: is it a good time to do such updating? Do I really need the React 18 features now? What profits does it bring to my project? Please take such updating as a huge task to accomplish.Code updatesApart from replacing ReactDOM.render with ReactDOMClient.createRoot, the whole bump entails code updatings, like:      Each browser’s event mock must be wrapped into act (as well as the mounting itself) if a component is run with createRoot in specs. Consider ~2k places you have to update to make specs green again. You may think a script which updates everything in less than a second with fancy regex may save us time. Believe me, ~10-15% of occurrences need special care. That means hours of debugging and figuring out what’s wrong with the spec setup or assertion.        Because unmountComponentAtNode is deprecated, a Root instance must be accessible on unmounting.Before, the obsolete API took a node and unmounted components at any time. Currently, the createRoot returns a Root object which has two methods: unmount and render. That’s the next reason for refactoring such places since direct access to a Root instance is needed.        I also discover issues with updates to a state with v18. The cause: one of the new features is in action: automatic batching. As alwyas, in such cases, you can disable it or refactor a component in question taking the new behavior into account. Disabling is done by flushSync helper.        Installed third-party libraries might not support React 18 at this time or never will. Some of them might have code built using outdated ideas and APIs. Without a general rewrite, they will no longer be able to support version 18 at all. Checking the cost of swapping out one package for another or making a contribution is highly advised. Note: NPM provides the —legacy-peer-deps switch; when used, it suppresses warnings for peerDependencies that are not supported.        If your project is a framework-like app, such as an SDK, and you need to support both v17 and v18 at the same time, this is today not possible in a clean way, in my opinion. The ‘createRoot’ function is imported from ‘react-dom/client’ while the ‘render’ function is imported from ‘react-dom’. You can try to devise various workarounds, such as exporting it from the same (sub)module or proxying it. Dynamic imports can also enter the game, although all solutions are basically hacks hard to maintain.        If you use a Node server as an app that generates a static markup or so, you will also need to update the API, eg. hydrate is now hydrateRoot. Some methods are marked deprecated compared to the v17 like renderToNodeStream, some are new like renderToPipeableStream. You have to delve into documentation and consider the usage which may cause side-effects you cannot expect.  Types updatesIf you use Typescript with React as I do, you must fix the issues that the most recent types package will point up, like:      There is no longer support for implicit children given to a component; this was convenient for devs using v17 or lower because it involved less code to write. Children must currently be explicitly declared in prop definitions or via one of the built-in types, such as PropsWithChildren. What was the motivation for the change? According to the author of the patch, implicit children are an excess prop (one that is sent to a component but is not actually handled by a component) that violates the POLA (principle of least astonishment rule of software design. The goal, as always, was to increase consistency and eliminate excesses.        No more React.SFC or React.StatelessComponent and similar types that start with SFC-. They’ve been replaced by React.FC / React.FunctionComponent. I delighted with the naming change, which was never correct in my opinion because ‘Stateless’ was a synonym for a function component, but nobody takes into account that class components might also be stateless. That was puzzling because the naming indicated the implementation detail.        An empty object {} is no longer supported as a legit ReactFragment. No explanation should be offered there, in my opinion, because it was never accurate because erroneous types might be rendered and TS did not complain but failed at runtime. AFAIK, it was the hack for implicit children.    The default type of ‘this.context’ is ‘unknown,’ not ‘any,’ which did not raise TS issues and was silent. The update was made in response to a request from the React community. In fact, this means that a suitable type must be introduced to a context wherever it is used.  There are more, non-critical changes to the type definitions as described above. For example, type deprecations. You may readily identify them by using codemod, a tool built by the author of these changes to types.Aside from code updates, the React types must be modified to reflect at least the primary changes. Regrettably, for large JS projects, TS is more rigorous now, and does not allow things that were permitted in v17 or below. This should be considered when comparing the TS rules followed in an app. What if the majority of the components need to be refactored or updated?Strict mode behaviorThe next, interesting thing is the strict mode that v18 offers. React, as docs states, in the further releases wants to ensure the reusable state. For that purpose, the newest StrictMode adds ‘strict mode effects’ that intentionally call side effects double times (mounting, unmounting, mounting) in dev mode. Some effects may not work as expected eg. subscriptions might be not properly destroyed in clean-up functions. This may make the strict mode off until callbacks are adjusted to the double invocation. If you enabled the mode in v18, the not properly cleaned subscriptions may entail additional refactorings.More pieces of adviceHere are some pointers for anyone thinking about bumping:      Check with your team if eg. upcoming sprint is the right moment for the fully bumping. Considering the task as large and potentially failing without code refactorings, type updates, or paying off tech debt. Is it more important to use the features that v18 delivers or is it a nice-to-have? Which issues will React 18 address in your project?        Evaluate the third-party libraries your app requires. Do they include v18 support in their bundle? Does the package.json - peerDependecies specify the latest React? How much work will it take to get them ready for version 18? Try updating them to the most recent versions and see whether everything works as it should. Even if the maintainers make them v18 compliant, you should upgrade them to the most recent version, before ensure that none of your features are broken. For a variety of reasons, legacy apps cannot bump certain of the packages, check if your software can manage that. Consider making contributions to other libraries that haven’t yet supported v18 but are required by your software. Keep in mind you can always use npm i --legacy-peer-deps to skip peerDependencies check.        Always stick to the official React docs and manuals regarding update commands you need to type in the terminal, skip tutorials that suggest crazy things.    Analyze the specs you have. Verify that act is used around each of the mocked events. All functions responsible for (re)rendering components must be compared with act and v18 is more strict in that matter, see act docs for further info. If your assertion fails without any reasons try to use act in your setup. Best if the React test recipes are followed.      Count the number of times your app uses deprecated API methods such as ReactDOM.render and ReactDOM.unmountComponentAtNode. Change them using the createRoot API. As the Root object must be accessible for the unmount method, refactoring is most likely required. I’d create a PR for each instance of the deprecation to guarantee that nothing breaks.        Apply the StrictMode immediately after the bump. It may benefit in finding unsupported methods and other issues; see the StrictMode documentation.        Determine how many Class components you still keep. If not too much, I’d focus on converting the most critical ones into functions: React.FC. I’ve noticed that hook-based components aren’t very verbose when it comes to warnings or errors.        If you’re using Typescript, you can utilize the codemod to highlight areas of your app that need to be tweaked. The most significant change is the removal of support for the implicit children prop. It must be stated explicitly.        You might not want to use the automatic batching feature. It could potentially be a reason for the spec failing. You can disable it by using the ‘flushSync’ helper, but keep in mind that it degrades performance,  see the docs of flushSync.    I would take care of any potential refactorings stated above before the React update, as they all make React 17 happy as well. You can interpret it as a bump preparations.SummaryWhat I like about software engineering is that it can be done incrementally. I recommend having a reliable plan in place to change the React version of an app smoothly and easily. The way that nobody noticed but your CI tools on performance score. In my case that was the most challenging React update I’ve ever made. If you are on the same task and need advice, you can try to reach me out.React 18 is great ;-)",
            "content_html": "<p>React 18 is out. I mean… it’s been available for over four months and I’ve just finished a kinda challenging process of migration from 17 to 18 in a huge JS app which is a mature SaaS product. I guess I completed it since you never know when the monster named tech debt could bite you. Anyways, I’d want to share some views on updating to 18v here, in the hopes that someone would find them useful.</p><p>If you’re unfamiliar with the topic of version 18, <a href=\"https://reactjs.org/blog/2022/03/29/react-v18.html\">read the official docs of the latest React</a>.</p><h2 id=\"the-new-api\">The new API</h2><p>Before considering bumping, please note - React’s most significant API has been modified. This means the commonly known and essential root mounting with <code class=\"language-plaintext highlighter-rouge\">ReactDOM.render</code> is deprecated. Of course, it’s still supported (due to backward compatibility), but it produces irritating warnings in production env and floods specs run. Hint: a crazy spy may save us from the warnings flood in a spec run, but nothing will help in production except replacing the old API with the desired new <code class=\"language-plaintext highlighter-rouge\">ReactDOMClient.createRoot</code>.</p><blockquote>  <p>Only the use of the createRoot API enables all React 18 features; otherwise, it behaves like v17. It’s not worth updating if you don’t have time to refactor.</p></blockquote><p>I once went to a tech conference where one of the speakers was convincing the audience that it’s not crazy to consider releasing tech products with a failure. Failures bring crises, crises - the best solutions. I don’t take a stupid warning a failure, but what is most important the API replacement may fail in big JS projects of course. I assume the cost of the bump, disappointment, wasted time, tech debt to pay off etc. Maybe it’s not worth making it at this time, following the YAGNI principle. So, before updating the API in crucial parts, consider what would your customers do if an app didn’t work for one hour? Especially when test coverages are not credible and only a happy path is checked on your CI. That was not my case, but it’s worth asking questions: is it a good time to do such updating? Do I really need the React 18 features now? What profits does it bring to my project? Please take such updating as a huge task to accomplish.</p><h2 id=\"code-updates\">Code updates</h2><p>Apart from replacing <code class=\"language-plaintext highlighter-rouge\">ReactDOM.render</code> with <code class=\"language-plaintext highlighter-rouge\">ReactDOMClient.createRoot</code>, the whole bump entails code updatings, like:</p><ul>  <li>    <p>Each browser’s event mock must be wrapped into <code class=\"language-plaintext highlighter-rouge\">act</code> (as well as the mounting itself) if a component is run with <code class=\"language-plaintext highlighter-rouge\">createRoot</code> in specs. Consider ~2k places you have to update to make specs green again. You may think a script which updates everything in less than a second with fancy regex may save us time. Believe me, ~10-15% of occurrences need special care. That means hours of debugging and figuring out what’s wrong with the spec setup or assertion.</p>  </li>  <li>    <p>Because <code class=\"language-plaintext highlighter-rouge\">unmountComponentAtNode</code> is deprecated, a <code class=\"language-plaintext highlighter-rouge\">Root</code> instance must be accessible on unmounting.Before, the obsolete API took a node and unmounted components at any time. Currently, the <code class=\"language-plaintext highlighter-rouge\">createRoot</code> returns a <code class=\"language-plaintext highlighter-rouge\">Root</code> object which has two methods: <code class=\"language-plaintext highlighter-rouge\">unmount</code> and <code class=\"language-plaintext highlighter-rouge\">render</code>. That’s the next reason for refactoring such places since direct access to a Root instance is needed.</p>  </li>  <li>    <p>I also discover issues with updates to a state with v18. The cause: one of the new features is in action: <a href=\"https://reactjs.org/blog/2022/03/08/react-18-upgrade-guide.html#automatic-batching\"><em>automatic batching</em></a>. As alwyas, in such cases, you can disable it or refactor a component in question taking the new behavior into account. Disabling is done by <code class=\"language-plaintext highlighter-rouge\">flushSync</code> helper.</p>  </li>  <li>    <p>Installed third-party libraries might not support React 18 at this time or never will. Some of them might have code built using outdated ideas and APIs. Without a general rewrite, they will no longer be able to support version 18 at all. Checking the cost of swapping out one package for another or making a contribution is highly advised. Note: NPM provides the —legacy-peer-deps switch; when used, it suppresses warnings for peerDependencies that are not supported.</p>  </li>  <li>    <p>If your project is a framework-like app, such as an SDK, and you need to support both v17 and v18 at the same time, this is today not possible in a clean way, in my opinion. The ‘createRoot’ function is imported from ‘react-dom/client’ while the ‘render’ function is imported from ‘react-dom’. You can try to devise various workarounds, such as exporting it from the same (sub)module or proxying it. Dynamic imports can also enter the game, although all solutions are basically hacks hard to maintain.</p>  </li>  <li>    <p>If you use a Node server as an app that generates a static markup or so, you will also need to update the API, eg. <code class=\"language-plaintext highlighter-rouge\">hydrate</code> is now <code class=\"language-plaintext highlighter-rouge\">hydrateRoot</code>. Some methods are marked deprecated compared to the v17 like <code class=\"language-plaintext highlighter-rouge\">renderToNodeStream</code>, some are new like <code class=\"language-plaintext highlighter-rouge\">renderToPipeableStream</code>. You have to delve into documentation and consider the usage which may cause side-effects you cannot expect.</p>  </li></ul><h2 id=\"types-updates\">Types updates</h2><p>If you use Typescript with React as I do, you must fix the issues that the most recent types package will point up, like:<br /></p><ul>  <li>    <p>There is no longer support for implicit children given to a component; this was convenient for devs using v17 or lower because it involved less code to write. Children must currently be explicitly declared in prop definitions or via one of the built-in types, such as <code class=\"language-plaintext highlighter-rouge\">PropsWithChildren</code>. What was the motivation for the change? According to the author of the patch, implicit children are an excess prop (one that is sent to a component but is not actually handled by a component) that violates the <a href=\"https://en.wikipedia.org/wiki/Principle_of_least_astonishment#:~:text=The%20principle%20of%20least%20astonishment,not%20astonish%20or%20surprise%20users.\">POLA (principle of least astonishment</a> rule of software design. The goal, as always, was to increase consistency and eliminate excesses.</p>  </li>  <li>    <p>No more <code class=\"language-plaintext highlighter-rouge\">React.SFC</code> or <code class=\"language-plaintext highlighter-rouge\">React.StatelessComponent</code> and similar types that start with <code class=\"language-plaintext highlighter-rouge\">SFC-</code>. They’ve been replaced by <code class=\"language-plaintext highlighter-rouge\">React.FC</code> / <code class=\"language-plaintext highlighter-rouge\">React.FunctionComponent</code>. I delighted with the naming change, which was never correct in my opinion because ‘Stateless’ was a synonym for a function component, but nobody takes into account that class components might also be stateless. That was puzzling because the naming indicated the implementation detail.</p>  </li>  <li>    <p>An empty object <code class=\"language-plaintext highlighter-rouge\">{}</code> is no longer supported as a legit <code class=\"language-plaintext highlighter-rouge\">ReactFragment</code>. No explanation should be offered there, in my opinion, because it was never accurate because erroneous types might be rendered and TS did not complain but failed at runtime. AFAIK, it was the hack for implicit children.</p>  </li>  <li>The default type of ‘this.context’ is ‘unknown,’ not ‘any,’ which did not raise TS issues and was silent. The update was made in response to a request from the React community. In fact, this means that a suitable type must be introduced to a context wherever it is used.</li>  <li>There are more, non-critical changes to the type definitions as described above. For example, type deprecations. You may readily identify them by using <a href=\"https://github.com/eps1lon/types-react-codemod\">codemod</a>, a tool built by the author of these changes to types.</li></ul><p>Aside from code updates, the React types must be modified to reflect at least the primary changes. Regrettably, for large JS projects, TS is more rigorous now, and does not allow things that were permitted in v17 or below. This should be considered when comparing the TS rules followed in an app. What if the majority of the components need to be refactored or updated?<br /></p><h2 id=\"strict-mode-behavior\">Strict mode behavior</h2><p>The next, interesting thing is the strict mode that v18 offers. React, as docs states, in the further releases wants to ensure <a href=\"https://reactjs.org/docs/strict-mode.html#ensuring-reusable-state\">the reusable state</a>. For that purpose, the newest StrictMode adds ‘strict mode effects’ that intentionally call side effects double times (mounting, unmounting, mounting) in dev mode. Some effects may not work as expected eg. subscriptions might be not properly destroyed in clean-up functions. This may make the strict mode off until callbacks are adjusted to the double invocation. If you enabled the mode in v18, the not properly cleaned subscriptions may entail additional refactorings.</p><h2 id=\"more-pieces-of-advice\">More pieces of advice</h2><p>Here are some pointers for anyone thinking about bumping:</p><ul>  <li>    <p>Check with your team if eg. upcoming sprint is the right moment for the fully bumping. Considering the task as large and potentially failing without code refactorings, type updates, or paying off tech debt. Is it more important to use the features that v18 delivers or is it a nice-to-have? Which issues will React 18 address in your project?</p>  </li>  <li>    <p>Evaluate the third-party libraries your app requires. Do they include v18 support in their bundle? Does the package.json - peerDependecies specify the latest React? How much work will it take to get them ready for version 18? Try updating them to the most recent versions and see whether everything works as it should. Even if the maintainers make them v18 compliant, you should upgrade them to the most recent version, before ensure that none of your features are broken. For a variety of reasons, legacy apps cannot bump certain of the packages, check if your software can manage that. Consider making contributions to other libraries that haven’t yet supported v18 but are required by your software. Keep in mind you can always use <code class=\"language-plaintext highlighter-rouge\">npm i --legacy-peer-deps</code> to skip <code class=\"language-plaintext highlighter-rouge\">peerDependencies</code> check.</p>  </li>  <li>    <p>Always stick to the official React docs and manuals regarding update commands you need to type in the terminal, skip tutorials that suggest crazy things.</p>  </li>  <li>Analyze the specs you have. Verify that <code class=\"language-plaintext highlighter-rouge\">act</code> is used around each of the mocked events. All functions responsible for (re)rendering components must be compared with act and v18 is more strict in that matter, see <a href=\"https://reactjs.org/docs/test-utils.html#act\">act docs</a> for further info. If your assertion fails without any reasons try to use <code class=\"language-plaintext highlighter-rouge\">act</code> in your setup. Best if the <a href=\"https://reactjs.org/docs/testing-recipes.html\">React test recipes</a> are followed.</li>  <li>    <p>Count the number of times your app uses deprecated API methods such as <code class=\"language-plaintext highlighter-rouge\">ReactDOM.render</code> and <code class=\"language-plaintext highlighter-rouge\">ReactDOM.unmountComponentAtNode</code>. Change them using the <code class=\"language-plaintext highlighter-rouge\">createRoot</code> API. As the <code class=\"language-plaintext highlighter-rouge\">Root</code> object must be accessible for the <code class=\"language-plaintext highlighter-rouge\">unmount</code> method, refactoring is most likely required. I’d create a PR for each instance of the deprecation to guarantee that nothing breaks.</p>  </li>  <li>    <p>Apply the <code class=\"language-plaintext highlighter-rouge\">StrictMode</code> immediately after the bump. It may benefit in finding unsupported methods and other issues; see the <a href=\"https://reactjs.org/docs/strict-mode.html\">StrictMode documentation</a>.</p>  </li>  <li>    <p>Determine how many Class components you still keep. If not too much, I’d focus on converting the most critical ones into functions: <code class=\"language-plaintext highlighter-rouge\">React.FC</code>. I’ve noticed that hook-based components aren’t very verbose when it comes to warnings or errors.</p>  </li>  <li>    <p>If you’re using Typescript, you can utilize the <a href=\"https://github.com/eps1lon/types-react-codemod\">codemod</a> to highlight areas of your app that need to be tweaked. The most significant change is the removal of support for the implicit children prop. It must be stated explicitly.</p>  </li>  <li>    <p>You might not want to use the automatic batching feature. It could potentially be a reason for the spec failing. You can disable it by using the ‘flushSync’ helper, but keep in mind that it degrades performance,  see the <a href=\"https://reactjs.org/docs/react-dom.html#flushsync\">docs of flushSync</a>.</p>  </li>  <li>I would take care of any potential refactorings stated above before the React update, as they all make React 17 happy as well. You can interpret it as a bump preparations.</li></ul><h2 id=\"summary\">Summary</h2><p>What I like about software engineering is that it can be done incrementally. I recommend having a reliable plan in place to change the React version of an app smoothly and easily. The way that nobody noticed but your CI tools on performance score. In my case that was the most challenging React update I’ve ever made. If you are on the same task and need advice, you can try to reach me out.</p><p>React 18 is great ;-)</p>",
            "url": "http://localhost:4000/2022/08/20/updating-to-react-18",
            
            
            
            "tags": ["JS","React","Typescript","React 18","ceateRoot API"],
            
            "date_published": "2022-08-20T00:00:00+02:00",
            "date_modified": "2022-08-20T00:00:00+02:00",
            
                "author":  {
                "name": "Patryk",
                "url": "boch.dev",
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2022/08/14/race-on-condiitons-in-rails",
            "title": "Race (on) condition(s) in Rails",
            "summary": "How to solve race condition problems in rails",
            "content_text": "Some argue that Ruby on Rails applications cannot scale. That is a common response given by candidates in job interviews when asked about the disadvantages of the framework. I don’t want to choose a side. I might respond, “it depends” - as always. Anyhow, if you want to prepare your app for receiving numerous requests at once, you need to consider the race condition issue which is liable to cause us troubles.I don’t want to delve into the definition of “race condition” as I’m sure my readers understand what it is because it is fundamental to software engineering. I’d like to concentrate on ways to get rid of this. If you’re unfamiliar and you want to discover more about the term’s origins, go here. Anyways, one line will adequately describe the problem.  When your app allows multiple requests to interact with the same records, and one request overrides changes made by another without taking them into account.For instance, if a large number of requests modify the same record at the same time in multi-users scenario.As my final point in this introduction, I want to emphasize that a database must ensure integrity of data, particularly when performing concurrent operations. Integrity introduces the ACID-compliant idea of “locking” into the picture. Because of this, both optimistic and pessimistic locking are considered as means of addressing race condition issues.Optimistic lockingOptimistic locking is when the version attribute maintained in a database column is taken into account. It’s the implicit technique of dodging the issue IMO. If we intend to use it, the special lock_version column needs to be added and Active Record, which is Rails’ default component, takes care of minimizing data conflicts.add_column :table_name, :lock_version, :integerEach time a record is updated, the lock_version entity is increased and the locking features make sure that records will only allow the last one stored to throw a StaleObjectError if there is a parallel update of any kind. Then, we can attempt updating the data again.Rails are adaptable; if you want to use your own table with a name that differs from lock_version you can do so by specyfing in your model:self.locking_column = :custom_lock_versionWhy is this type of dealing with race condition regarded as optimistic? Because it is assumed that database conflicts occur less frequently. Optimistic locking performs by simply comparing the “version” column value. As a result, it does not represent a true database lock.Pessimistic lockingPessimistic locking, on the other hand, is a technique that counts on more frequent database conflicts. Since it offers an exclusive lock on the record, it is regarded as more explicit. When a single request modifies a record, it locks it until a transaction is completed. For this purpose a built-in methods with_lock and #lock! are used. Both operate similarly to each other. The main difference is that the #lock! needs to be used within an Active Record’s transaction since it is unlocked again when the surrounding transaction is finished; sadly, using it outside the transaction block is ineffective. The with_lock method initiates a database transaction by itself. Anyways, all methods prevent others from reading or writing a record until the transaction is completed.See the with_lock API reference.What to choose?Both locking methods are regarded as useful; however, the cost of a transaction retry must be considered when selecting a suitable locking scheme. It is determined by app requirements and business logic. Let’s summarize these two approaches briefly.            Optimistic locking      Pessimistic locking                  Locks a record once changes are comitted to db      Locks record once it is edited              Considers data conflicts less frequently      Considers data conflicts more frequently              Needs a version number stored in a db column for locking a record      Needs an invocation of with_lock or #lock! methods for locking a record              Allows a conflict to occur and may retry or throw an error      Blocks conflicts until a record is unlocked (a transaction is done)              Is used once a cost of retry is low      Is used once a cost of retry is high      Rather than locking a record for entire transactions by pessimistic way, I’d take the optimistic approach and that’s what I recommend. As alwyas, at the end, it depends on the use case that may force the pessimistic approach.There are more methods besides optimism and pessimism to stay away from race conditions. Since more libraries need to be installed, let’s quickly go over the details of two additional, more particular approaches.What else?Advisory lockingAnother useful technique is the advisory locking. It doesn’t lock records but guarantees that no two processes operate another process at the same time (by adding mutexes). In order to do so you’d need to extend an app with with_advisory_lock gem. See official docs for details.Background processing and queuesI’m sure that all readers know what background processing is as it’s fundamental. In ruby apps Sidekiq is used frequently to handle background jobs that may alter db records. An extension to Sidekiq - SidekiqUniqueJobs adds extra constraints and prevents from race conditions there. The configuration is pretty straight forward since only an extra middleware must be configured. See official docs for details.SummaryIt may be difficult to create consistent systems without problems with data integrity so knowing strategies that let us avoid race conditions are desirable. Of course, there are more locking strategies, but I’ve only shown those that I find most useful in my day-to-day work as a developer.",
            "content_html": "<p>Some argue that Ruby on Rails applications cannot scale. That is a common response given by candidates in job interviews when asked about the disadvantages of the framework. I don’t want to choose a side. I might respond, “it depends” - as always. Anyhow, if you want to prepare your app for receiving numerous requests at once, you need to consider the <em>race condition</em> issue which is liable to cause us troubles.</p><p>I don’t want to delve into the definition of “race condition” as I’m sure my readers understand what it is because it is fundamental to software engineering. I’d like to concentrate on ways to get rid of this. If you’re unfamiliar and you want to discover more about the term’s origins, go <a href=\"https://devopedia.org/race-condition-software\">here</a>. Anyways, one line will adequately describe the problem.</p><blockquote>  <p>When your app allows multiple requests to interact with the same records, and one request overrides changes made by another without taking them into account.</p></blockquote><p>For instance, if a large number of requests modify the same record at the same time in multi-users scenario.</p><p>As my final point in this introduction, I want to emphasize that a database must ensure integrity of data, particularly when performing concurrent operations. Integrity introduces the ACID-compliant idea of “locking” into the picture. Because of this, both optimistic and pessimistic locking are considered as means of addressing race condition issues.</p><h2 id=\"optimistic-locking\">Optimistic locking</h2><p>Optimistic locking is when the version attribute maintained in a database column is taken into account. It’s the implicit technique of dodging the issue IMO. If we intend to use it, the special <em>lock_version</em> column needs to be added and Active Record, which is Rails’ default component, takes care of minimizing data conflicts.</p><div class=\"language-ruby highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">add_column</span> <span class=\"ss\">:table_name</span><span class=\"p\">,</span> <span class=\"ss\">:lock_version</span><span class=\"p\">,</span> <span class=\"ss\">:integer</span></code></pre></div></div><p>Each time a record is updated, the <code class=\"language-plaintext highlighter-rouge\">lock_version</code> entity is increased and the locking features make sure that records will only allow the last one stored to throw a <code class=\"language-plaintext highlighter-rouge\">StaleObjectError</code> if there is a parallel update of any kind. Then, we can attempt updating the data again.</p><script src=\"https://gist.github.com/patrykboch/99296a4395b362ed3dbd279adedf02b1.js\"></script><p>Rails are adaptable; if you want to use your own table with a name that differs from <em>lock_version</em> you can do so by specyfing in your model:</p><div class=\"language-ruby highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">self</span><span class=\"p\">.</span><span class=\"nf\">locking_column</span> <span class=\"o\">=</span> <span class=\"ss\">:custom_lock_version</span></code></pre></div></div><p>Why is this type of dealing with race condition regarded as optimistic? Because it is assumed that database conflicts occur less frequently. Optimistic locking performs by simply comparing the “version” column value. As a result, it does not represent a true database lock.</p><h2 id=\"pessimistic-locking\">Pessimistic locking</h2><p>Pessimistic locking, on the other hand, is a technique that counts on more frequent database conflicts. Since it offers an exclusive lock on the record, it is regarded as more explicit. When a single request modifies a record, it locks it until a transaction is completed. For this purpose a built-in methods <code class=\"language-plaintext highlighter-rouge\">with_lock</code> and <code class=\"language-plaintext highlighter-rouge\">#lock!</code> are used. Both operate similarly to each other. The main difference is that the <code class=\"language-plaintext highlighter-rouge\">#lock!</code> needs to be used within an Active Record’s transaction since it is unlocked again when the surrounding transaction is finished; sadly, using it outside the transaction block is ineffective. The <code class=\"language-plaintext highlighter-rouge\">with_lock</code> method initiates a database transaction by itself. Anyways, all methods prevent others from reading or writing a record until the transaction is completed.</p><script src=\"https://gist.github.com/patrykboch/0ec6ae5943fc43331771a34ac1df9fe2.js\"></script><p><a href=\"https://api.rubyonrails.org/classes/ActiveRecord/Locking/Pessimistic.html\">See the <code class=\"language-plaintext highlighter-rouge\">with_lock</code> API reference</a>.</p><h2 id=\"what-to-choose\">What to choose?</h2><p>Both locking methods are regarded as useful; however, the cost of a transaction retry must be considered when selecting a suitable locking scheme. It is determined by app requirements and business logic. Let’s summarize these two approaches briefly.<br /><br /></p><table>  <thead>    <tr>      <th>Optimistic locking</th>      <th>Pessimistic locking</th>    </tr>  </thead>  <tbody>    <tr>      <td>Locks a record once changes are comitted to db</td>      <td>Locks record once it is edited</td>    </tr>    <tr>      <td>Considers data conflicts less frequently</td>      <td>Considers data conflicts more frequently</td>    </tr>    <tr>      <td>Needs a version number stored in a db column for locking a record</td>      <td>Needs an invocation of <code class=\"language-plaintext highlighter-rouge\">with_lock</code> or <code class=\"language-plaintext highlighter-rouge\">#lock!</code> methods for locking a record</td>    </tr>    <tr>      <td>Allows a conflict to occur and may retry or throw an error</td>      <td>Blocks conflicts until a record is unlocked (a transaction is done)</td>    </tr>    <tr>      <td>Is used once a cost of retry is low</td>      <td>Is used once a cost of retry is high</td>    </tr>  </tbody></table><p><br />Rather than locking a record for entire transactions by pessimistic way, I’d take the optimistic approach and that’s what I recommend. As alwyas, at the end, it depends on the use case that may force the pessimistic approach.</p><p>There are more methods besides optimism and pessimism to stay away from race conditions. Since more libraries need to be installed, let’s quickly go over the details of two additional, more particular approaches.</p><h2 id=\"what-else\">What else?</h2><h3 id=\"advisory-locking\">Advisory locking</h3><p>Another useful technique is the advisory locking. It doesn’t lock records but guarantees that no two processes operate another process at the same time (by adding mutexes). In order to do so you’d need to extend an app with <a href=\"https://github.com/ClosureTree/with_advisory_lock\"><em>with_advisory_lock</em></a> gem. See official docs for details.</p><h3 id=\"background-processing-and-queues\">Background processing and queues</h3><p>I’m sure that all readers know what background processing is as it’s fundamental. In ruby apps Sidekiq is used frequently to handle background jobs that may alter db records. An extension to Sidekiq - <a href=\"https://github.com/mhenrixon/sidekiq-unique-jobs\">SidekiqUniqueJobs</a> adds extra constraints and prevents from race conditions there. The configuration is pretty straight forward since only an extra middleware must be configured. See official docs for details.</p><h2 id=\"summary\">Summary</h2><p>It may be difficult to create consistent systems without problems with data integrity so knowing strategies that let us avoid race conditions are desirable. Of course, there are more locking strategies, but I’ve only shown those that I find most useful in my day-to-day work as a developer.</p>",
            "url": "http://localhost:4000/2022/08/14/race-on-condiitons-in-rails",
            
            
            
            "tags": ["ruby","rails","race condition","optimistic lock","pessimistic lock"],
            
            "date_published": "2022-08-14T00:00:00+02:00",
            "date_modified": "2022-08-14T00:00:00+02:00",
            
                "author":  {
                "name": "Patryk",
                "url": "boch.dev",
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2022/08/12/proxy-as-the-way-of-metaprogramming-in-js",
            "title": "Proxy as the way of metaprogramming in JS",
            "summary": "How to use Proxy es6 object in JS for metaprogramming",
            "content_text": "Important note: Described Proxy object is something different than one of the OOP patterns.I’ve seen several odd JS characteristics ever since I started using it on a daily basis. One of these irritates me — undefined rather than a code execution error when attempting to access properties that don’t exist. In this regard, JS behaves somewhat differently from my experience with Ruby:and a Ruby equivalent:The error throw is produced by Ruby, but JS returns undefined. Imagine working on a large JS project and a simple property typo results in an app being broken because undefined was used instead of the key not found throw. You would not know why or where this happened because undefined may appear throughout many different places (debugging undefined may take a long time). Fortunately, the built-in Proxies objects provided by the ES6+ standard provide a solution to the concern.Since the release of ES6, JS is known as fully reflective programming language as the Reflection API has been advanced.  Reflection is the ability of a computer program to examine, introspect, and modify its own structure and behavior at runtime.That implies that a program can execute on each of the three levels mentioned. Please be aware that ES5 has provided the potential of reflective introspection and self-modification - Object.keys() for introspection or Object#delete for self-modification - also all Object.* methods are taken as reflective for metaprogramming, but neither they nor other ES5 features support the third level of reflection - behavioral level which is the reason for the introduction of proxies in ES6 that alter built-in language operations.  The Proxy object is used to define custom behavior for fundamental operations (e.g. property lookup, assignment, enumeration, function invocation, etc). (official docs)Using proxies is a way for virtualizing objects eg. POJOs. Virtualized object peeks the same as a given object, and any operation on a given one directs to an already created virtualized by a proxy object. By virtualization, we can take control of standard methods default behavior by intercepting invocations and re-defining them.Nothing special above, virtualization of the object and the property lookup without invoking any operations(see: no-op forwarding). When you add a property to an object, the same property is added to the proxy object. Although it is a symlink, proxies are designed to intercept low-level operations on the target object.Error instead of undefined…when accessing non-existent property with the get trap.Let’s solve the issue that is raised at the beginning of the post. How can the default behavior, which terminates in undefined be changed to an error caused by code execution like in Ruby or Python? Let’s start by describing the default behavior using a proxy object:Let’s change the default behaviour:I passed the trap the following three arguments: 1) the target object for the proxy is denoted the trapTarget 2) the key - the property and 3) the receiver - the proxy reference. The js object Reflect, which describes the default behavior of js. Please note there is a Reflect technique for each proxy trap.To recap, operations can be intercepted using a handler and a proxy trap, which is a function that is always supplied as the second proxy argument and is in charge of the operation.  I’ve shown two branches on the diagram: the default behavior and the proxy’s interception of the default behavior.On the most fundamental level, default reflection yields undefined. The same outcome is also possible with a proxy.The second branch - Proxy intercepts default behaviour by get trap in the handler and raises an error in the code example if property doesn’t exist.Note: get trap is one of many others traps - see all available traps for the Proxy.Building two-way data binding using ProxyMoving on let’s dive into a more complex thing. If you’re familiar with AngularJS or VueJS you’re probably into two-way data binding concept as it’s the main philosophy of these frameworks (see AngularJS docs or VueJs example of v-model)  Two-way-data binding links the state with the view. If the state changes the view is updated and if the view changes the state will be updated.Using Proxy is the way to go if you want to create your own two-way data binding-based js framework. Our view can be connected to application state through a proxy. Consider the following illustration:see live exampleThe state and the view are now bound. The view alters as the state does. First, I gave the DOM input elements a brand-new attribute called data-model. The key component of two-way data binding is the model, which connects input value and app state. After that, I created the straightforward state interface with two keys (name and hobby).It’s good to note that only keys that have been set in the interface can be modified in a proxy; otherwise, an error will be raised if eg. state.strangerKey = \"Hello\". The next step is to build a proxy that has a set trap in the handler; updateView is added between calls to the default engine set behavior, which means that each time the state is attempted to be changed, the input values in the view will also be altered. From a view to a state direction. Also listeners have been provided to the view that detect input value changes and trigger the state change. So registering listeners on DOM elements is crucial because only registered listeners can change the state via the onInputChange event handler.For now, the journey with Proxy wound up, I’ve presented the most common proxy traps - get and set but keep in mind that Proxy supports twelve more handlers which can be used for different purposes, especially in metaprogramming.PS. Metaprogramming rocks :).",
            "content_html": "<p>Important note: Described <em>Proxy</em> object is something different than one of the OOP patterns.</p><p>I’ve seen several odd JS characteristics ever since I started using it on a daily basis. One of these irritates me — <code class=\"language-plaintext highlighter-rouge\">undefined</code> rather than a code execution error when attempting to access properties that don’t exist. In this regard, JS behaves somewhat differently from my experience with Ruby:</p><script src=\"https://gist.github.com/patrykboch/48bf5dd1f626c2c889c8bfa43931dd51.js\"></script><p>and a Ruby equivalent:</p><script src=\"https://gist.github.com/patrykboch/c29bb0a5faacee9c1548c23eb4eff44b.js\"></script><p>The error throw is produced by Ruby, but JS returns <code class=\"language-plaintext highlighter-rouge\">undefined</code>. Imagine working on a large JS project and a simple property typo results in an app being broken because <code class=\"language-plaintext highlighter-rouge\">undefined</code> was used instead of the <em>key not found</em> throw. You would not know why or where this happened because <code class=\"language-plaintext highlighter-rouge\">undefined</code> may appear throughout many different places (debugging undefined may take a long time). Fortunately, the built-in Proxies objects provided by the ES6+ standard provide a solution to the concern.</p><p>Since the release of ES6, JS is known as fully reflective programming language as the <em>Reflection API</em> has been advanced.</p><blockquote>  <p>Reflection is the ability of a computer program to examine, introspect, and modify its own structure and behavior at runtime.</p></blockquote><p>That implies that a program can execute on each of the three levels mentioned. Please be aware that ES5 has provided the potential of reflective introspection and self-modification - <code class=\"language-plaintext highlighter-rouge\">Object.keys()</code> for introspection or <code class=\"language-plaintext highlighter-rouge\">Object#delete</code> for self-modification - also all <code class=\"language-plaintext highlighter-rouge\">Object.*</code> methods are taken as reflective for metaprogramming, but neither they nor other ES5 features support the third level of reflection - <em>behavioral level</em> which is the reason for the introduction of proxies in ES6 that alter built-in language operations.</p><blockquote>  <p>The Proxy object is used to define custom behavior for fundamental operations (e.g. property lookup, assignment, enumeration, function invocation, etc). <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Meta_programming\">(official docs)</a></p></blockquote><p>Using proxies is a way for virtualizing objects eg. POJOs. Virtualized object peeks the same as a given object, and any operation on a given one directs to an already created virtualized by a proxy object. By virtualization, we can take control of standard methods default behavior by intercepting invocations and re-defining them.</p><script src=\"https://gist.github.com/patrykboch/cf189feaad1e574d01194ff9d9a04a31.js\"></script><p>Nothing special above, virtualization of the object and the property lookup without invoking any operations(see: <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy#No-op_forwarding_proxy\">no-op forwarding</a>). When you add a property to an object, the same property is added to the proxy object. Although it is a symlink, proxies are designed to intercept low-level operations on the target object.</p><h2 id=\"error-instead-of-undefined\">Error instead of undefined</h2><p><em>…when accessing non-existent property with the <code class=\"language-plaintext highlighter-rouge\">get</code> trap.</em></p><p>Let’s solve the issue that is raised at the beginning of the post. How can the default behavior, which terminates in <code class=\"language-plaintext highlighter-rouge\">undefined</code> be changed to an error caused by code execution like in Ruby or Python? Let’s start by describing the default behavior using a proxy object:</p><script src=\"https://gist.github.com/patrykboch/d069e35aaf76b55c5f75ffe6a35eef34.js\"></script><p>Let’s change the default behaviour:</p><script src=\"https://gist.github.com/patrykboch/3e2608d8ba474e311066d7bafe06127e.js\"></script><p>I passed the trap the following three arguments: 1) the target object for the proxy is denoted the <code class=\"language-plaintext highlighter-rouge\">trapTarget</code> 2) the <code class=\"language-plaintext highlighter-rouge\">key</code> - the property and 3) the <code class=\"language-plaintext highlighter-rouge\">receiver</code> - the proxy reference. The js object <code class=\"language-plaintext highlighter-rouge\">Reflect</code>, which describes the default behavior of js. Please note there is a <code class=\"language-plaintext highlighter-rouge\">Reflect</code> technique for each proxy trap.</p><p>To recap, operations can be intercepted using a handler and a proxy trap, which is a function that is always supplied as the second proxy argument and is in charge of the operation.<br /> <br /></p><center><div class=\"mxgraph\" style=\"max-width:100%;border:1px solid transparent;\" data-mxgraph=\"{&quot;highlight&quot;:&quot;#0000ff&quot;,&quot;lightbox&quot;:false,&quot;nav&quot;:true,&quot;resize&quot;:true,&quot;toolbar&quot;:&quot;zoom&quot;,&quot;edit&quot;:&quot;_blank&quot;,&quot;xml&quot;:&quot;&lt;mxfile modified=\\&quot;2019-04-28T10:57:51.851Z\\&quot; host=\\&quot;www.draw.io\\&quot; agent=\\&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36\\&quot; etag=\\&quot;KT1R89YZZIPHrD0EufzU\\&quot; version=\\&quot;10.6.5\\&quot; type=\\&quot;device\\&quot;&gt;&lt;diagram id=\\&quot;lh_yR_ml-EyFlSGjHwGa\\&quot; name=\\&quot;Page-1\\&quot;&gt;3VnfU+IwEP5rmLl70GmbttBHFfUevNE7nbnTt0BDG680TAhC/esvoUl/JMWCUnR4orvdbpJv90t2Qw9cTFfXFM7inyRESc+xwlUPDHuOY7vBgP8ITZZrAiEJRURxKI1KxT1+RVJpSe0Ch2heM2SEJAzP6soxSVM0ZjUdpJQs62YTktRHncEIGYr7MUxM7R8csjjXDjyr1P9AOIrVyLYl30yhMpaKeQxDsqyowGUPXFBCWP40XV2gRICncMm/u9rwtpgYRSnb5oMgunGePHobXi+sx+df/5wna3Di515eYLKQC76dIQoZJqmcNcsUFMsYM3Q/g2MhL3m4e+A8ZtOESzZ/lJ4QZWi1cYp2sXCeMYhMEaMZN5EfOArWTKWPlJcl9AXAcQV2ZQdltKPCdQkIf5CY7IBP38DnN5ovEvYJ4HiDrwbOwADHgAWFnE1SRMmILC9LxflawV8IWDCnXB0yShZpiMT4VgGgcPc2fHx0sqBj1J7zDNIIsbbYm+GgKOH8eKnPownb9adnlMKsYjAjOGXziuc7oSijDFwtyr7Gas3e7TdnRRnXfAZllIulvD/wanM+SOR5fGn2VwinwFHyI5dPrFPLU4rhqmo+zKrSHaKYLxlRpVxhljt0PCk+yqHFc+lKCFlHCfjRxDIyoTgyVSYMNN7n85JfvZVSrlNz5PiDuqOcOYajXVPd1SZsHGA6NbQNUC144zp0/1aLf78ZwG3no1G1I+rZh6ReQRTfrTJFMK+gTjNdhGDwrmSyVyWy3ULi7al3mD29YRP2NMYE76OerxdAOof3RD29lmijnuftRj2gn0pBi32g2fcPQSXXoNKUhHjCWdFY//LSjWlsQXP8CkdrA5GoEnZu7Z33vCHXwAUj87ypER/ABEcpf07QRLhSHDyTakZE2TjnVSROowchDE/c/VSPrlNPUeCY1WPQUDw6XRWPtllah2gC17W1NUIxfMGE9sTwV2uCThLe3q3D4icCuxF/6UdsjY6pOabQGeQADYW/3xA70FnszMqfo4f4Fjc7PuboZYHTAP+gAX27M/QDA/35DI3FxiWoAxV1jikIntUehMbmt7MoALMQexBt/+EvBow6t78lNp1dDADzZL2jZJV9+35cWVlkYaahXEHeO2hSmoeqgXi1OyCUxSQiKUyqLUK9CShtbsgaPYH5M2Isk7e1IhxNSb2XXhnIsqW1st9LU71rHe1odXRLmfu2eTdVrgKwesU7ehZX5YffqfT73U+/wVQ3HZ/Ml7LP7m9/IVXppvu1drpsoD/aTn8xdpp8Chr5tHPbrfuxPc3RntpuoDVhqpLf2Ba/bd/NhuECgxMxTMMEHVlJaQQ98IzdqKmresfhzcXyf748TuW/peDyPw==&lt;/diagram&gt;&lt;/mxfile&gt;&quot;}\"></div><script type=\"text/javascript\" src=\"https://www.draw.io/js/viewer.min.js\"></script></center><p><br /> <br /></p><p>I’ve shown two branches on the diagram: the default behavior and the proxy’s interception of the default behavior.On the most fundamental level, default reflection yields <code class=\"language-plaintext highlighter-rouge\">undefined</code>. The same outcome is also possible with a proxy.</p><p>The second branch - <code class=\"language-plaintext highlighter-rouge\">Proxy</code> intercepts default behaviour by get trap in the handler and raises an error in the code example if property doesn’t exist.Note: <code class=\"language-plaintext highlighter-rouge\">get</code> trap is one of many others traps - <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy#Methods_of_the_handler_object\">see all available traps for the <code class=\"language-plaintext highlighter-rouge\">Proxy</code></a>.</p><h2 id=\"building-two-way-data-binding-using-proxy\">Building two-way data binding using <em>Proxy</em></h2><p>Moving on let’s dive into a more complex thing. If you’re familiar with AngularJS or VueJS you’re probably into two-way data binding concept as it’s the main philosophy of these frameworks (see <a href=\"https://docs.angularjs.org/guide/databinding\">AngularJS</a> docs or <a href=\"https://vuejs.org/v2/guide/forms.html\">VueJs example of <em>v-model</em></a>)</p><blockquote>  <p>Two-way-data binding links the state with the view. If the state changes the view is updated and if the view changes the state will be updated.</p></blockquote><p>Using Proxy is the way to go if you want to create your own two-way data binding-based js framework. Our view can be connected to application state through a proxy. Consider the following illustration:<script src=\"https://gist.github.com/patrykboch/3d7b1627643facc4cbdf0ba273d4a877.js\"></script><script src=\"https://gist.github.com/patrykboch/13f5bd92ce082e698aabe2f90032e173.js\"></script><a href=\"https://jsfiddle.net/edzv5L0q/\">see live example</a></p><p>The state and the view are now bound. The view alters as the state does. First, I gave the DOM input elements a brand-new attribute called <code class=\"language-plaintext highlighter-rouge\">data-model</code>. The key component of two-way data binding is the model, which connects input value and app state. After that, I created the straightforward state interface with two keys (name and hobby).It’s good to note that only keys that have been set in the interface can be modified in a proxy; otherwise, an error will be raised if eg. <code class=\"language-plaintext highlighter-rouge\">state.strangerKey = \"Hello\"</code>. The next step is to build a proxy that has a <code class=\"language-plaintext highlighter-rouge\">set</code> trap in the handler; <code class=\"language-plaintext highlighter-rouge\">updateView</code> is added between calls to the default engine set behavior, which means that each time the state is attempted to be changed, the input values in the view will also be altered. From a view to a state direction. Also listeners have been provided to the view that detect input value changes and trigger the state change. So registering listeners on DOM elements is crucial because only registered listeners can change the state via the <code class=\"language-plaintext highlighter-rouge\">onInputChange</code> event handler.</p><p>For now, the journey with Proxy wound up, I’ve presented the most common proxy traps - <code class=\"language-plaintext highlighter-rouge\">get</code> and <code class=\"language-plaintext highlighter-rouge\">set</code> but keep in mind that Proxy supports twelve more handlers which can be used for different purposes, especially in metaprogramming.</p><p>PS. Metaprogramming rocks :).<br /></p>",
            "url": "http://localhost:4000/2022/08/12/proxy-as-the-way-of-metaprogramming-in-js",
            
            
            
            "tags": ["js","proxy","metaprogramming","reflect"],
            
            "date_published": "2022-08-12T00:00:00+02:00",
            "date_modified": "2022-08-12T00:00:00+02:00",
            
                "author":  {
                "name": "Patryk",
                "url": "boch.dev",
                "avatar": null
                }
                
            
        }
    
    ]
}